{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jashan36879/GenAI/blob/main/GenAI_image_video_animation_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Title of the Project: Creating Pictures and Videos with generative AI\n",
        "\n",
        "## Brief Description\n",
        "This project is about using AI to make pictures and videos based on written instructions. We're using a tool called Replicate to do this. The project will show how well AI can understand and create visuals from text. We'll make images, animations, and try changing them to see what happens.\n",
        "\n",
        "# Group Members' Information\n",
        "\n",
        "## Group Members\n",
        "1. **Name:** Jashandeep Singh , ID: 4355433\n",
        "\n",
        "# Detailed Project Description\n",
        "\n",
        "## Project Overview\n",
        "In this project, we explore the capabilities of Replicate for AI-driven image synthesis and animation generation. The process involves utilizing pre-trained models for both static image creation and dynamic animations. The generated content is then analyzed for its realism and applicability in diverse scenarios.\n",
        "\n",
        "### Objectives and Expected Outcomes\n",
        "We want to see how good AI is at making pictures and videos from text. With Replicate, we aim to:\n",
        "\n",
        "- Make good pictures based on what's written.\n",
        "- Create animations showing different scenes.\n",
        "- Check if the pictures and videos make sense.\n",
        "- Try changing them to make them better or different.\n",
        "\n",
        "We expect to:\n",
        "\n",
        "- Make pictures and animations successfully.\n",
        "- See if they look right and make sense.\n",
        "- Try different things to see what works best.\n",
        "- Write down what we did and what we found out.\n",
        "\n",
        "---\n",
        "\n",
        "# Modification/New Addition Specification\n",
        "\n",
        "## Modifications/New Additions:\n",
        "We propose the addition of a feature to allow users to customize the style of generated images and videos. This will involve integrating style transfer techniques into the existing pipeline, enabling users to specify the desired artistic style for the generated content.\n",
        "\n",
        "##Impact:\n",
        "- Enhances the creative potential of the platform by enabling users to infuse their preferred artistic styles into the generated content.\n",
        "- Offers users more control and flexibility over the output, leading to a more personalized and engaging experience.\n",
        "---\n",
        "\n",
        "# Criteria-Specific\n",
        "\n",
        "##Relevance and Application:\n",
        "For our project about AI creating visuals, important things are:\n",
        "\n",
        "- How well the pictures and videos match the instructions.\n",
        "- If the AI can understand different kinds of instructions.\n",
        "- How good we are at using the tools and making things work.\n",
        "##Innovation and Technical Proficiency:\n",
        "We'll show new things by:\n",
        "\n",
        "- Trying different instructions to see what comes out.\n",
        "- Using advanced tools to get better results.\n",
        "- Checking if the pictures and videos look good and make sense.\n",
        "\n",
        "---\n",
        "\n",
        "# Reference\n",
        "1. Fardousi, T. (2023, October 5). Generating images, videos, and animations with the stable diffusion model via replicate API in... Medium. https://medium.com/@turna.fardousi/generating-images-videos-and-animations-with-the-stable-diffusion-model-via-replicate-api-in-d6d6bb3a7601\n",
        "\n",
        "2. Replicate Documentation: Replicate. https://replicate.com/docs/get-started/python\n",
        "\n",
        "3. Google Colaboratory. (n.d.). https://colab.research.google.com/drive/1-7QeW2EQPggRwT0ddmwqwT5veM09xtQW?usp=sharing\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "M49lstKso4R4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-f4rzIDbk8n",
        "outputId": "6ce4a6d7-e43d-449a-8480-f995ac0335fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.25.1-py3-none-any.whl (39 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.6.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.10.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.16.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 replicate-0.25.1\n"
          ]
        }
      ],
      "source": [
        "# @title Step 1. Install Replicate\n",
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation: This line installs the Replicate Python package using pip. Replicate is a platform for running AI models and experiments"
      ],
      "metadata": {
        "id": "03xL0Alon2h6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cFmhr3PSf4G2"
      },
      "outputs": [],
      "source": [
        "# @ title Step 2. Token\n",
        "API = \"r8_bLOMHglj4rXxbOBeXuW9WMUwgIoOIcL2RRJQ2\" # @param {type:\"string\"}\n",
        "import os\n",
        "\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = API #find it here: https://replicate.com/signin?next=/account/api-tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation:Here, you set up your Replicate API token. This token is necessary for authenticating and accessing Replicate's services. The token is stored in the environment variable REPLICATE_API_TOKEN"
      ],
      "metadata": {
        "id": "sFTSpliVoGgA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zz83wA6cqSF",
        "outputId": "134995cc-8a19-4f46-d67d-7957c20a4fd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://replicate.delivery/pbxt/ZPgf4k2YCuzRCyGGcLbokpxBGKfCdIhKzRtOTdJGD2j6ReLlA/out-0.png']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# @title Step 3. Generate Impage\n",
        "prompt = \"wearing a VR headset\" # @param {type:\"string\"}\n",
        "import replicate\n",
        "\n",
        "output = replicate.run(\n",
        "  \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\",\n",
        "  input={\"prompt\":prompt}\n",
        ")\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation: This step generates an image based on the provided prompt using a specific AI model. The replicate.run function is called with the model identifier and the input prompt. The generated image is stored in the output variable."
      ],
      "metadata": {
        "id": "99b2KkrToOPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "hwXEISnemCLj",
        "outputId": "e5ffc5ac-ee41-416b-dbd8-e4792696478b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://replicate.delivery/pbxt/ZPgf4k2YCuzRCyGGcLbokpxBGKfCdIhKzRtOTdJGD2j6ReLlA/out-0.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# @title Step 4. Show image\n",
        "from IPython.display import Image\n",
        "output_image = output\n",
        "Image(url=output_image[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation: Here, the generated image is displayed using the Image function from IPython.display. The URL of the generated image is retrieved from the output variable and passed to the Image function."
      ],
      "metadata": {
        "id": "0HNTesaHoSYo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Misa5E4QiWNZ",
        "outputId": "cfb30588-bc83-4aaf-92dc-d35383d47fd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Prediction.output_iterator at 0x7ae8fff9e8f0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# @title Step 5. Video/gif/animation/Generation\n",
        "import replicate\n",
        "\n",
        "output = replicate.run(\n",
        "    \"andreasjansson/stable-diffusion-animation:ca1f5e306e5721e19c473e0d094e6603f0456fe759c10715fcd6c1b79242d4a5\",\n",
        "    input={\n",
        "        \"prompt_start\": \"wearing a VR headset\",\n",
        "        \"prompt_end\": \"Removing a VR headset\",\n",
        "        \"output_format\": \"gif\",\n",
        "        \"gif_ping_pong\": True\n",
        "    }\n",
        ")\n",
        "\n",
        "output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation: This step generates a video, GIF, or animation based on start and end prompts using another AI model. Similar to Step 3, the replicate.run function is called with the appropriate model identifier and input parameters"
      ],
      "metadata": {
        "id": "tlvYwhh7oVq_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB0LZJTyjA7Z",
        "outputId": "5be7ea10-0b77-4eb1-dc3c-0a8d57226a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://replicate.delivery/pbxt/3Bg4k2caU9qqH56beCgTaZLLUaLvFA02OFe4PNU8cZeAs8LlA/video.gif\n"
          ]
        }
      ],
      "source": [
        "# @title Step 6. generate video\n",
        "for item in output:\n",
        "     #https://replicate.com/andreasjansson/stable-diffusion-animation/versions/ca1f5e306e5721e19c473e0d094e6603f0456fe759c10715fcd6c1b79242d4a5/api#output-schema\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:This step prints the output of the video generation process. The output typically contains information about the generated video, such as its URL."
      ],
      "metadata": {
        "id": "kNNm0SY7oY1P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fuPgsixhkxM4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Step 7. get the video on colab\n",
        "gif_url= item[0:len(item)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:This step retrieves the URL of the generated video from the output and stores it in the variable gif_url."
      ],
      "metadata": {
        "id": "w6fZwjtKoggI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "6VPPvsE3km93",
        "outputId": "462fba7a-2176-4e7b-c726-4876c4232026",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://replicate.delivery/pbxt/3Bg4k2caU9qqH56beCgTaZLLUaLvFA02OFe4PNU8cZeAs8LlA/video.gif\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Step 8. Show the video\n",
        "import requests\n",
        "from IPython.display import display, Image\n",
        "from PIL import Image as PILImage\n",
        "from io import BytesIO\n",
        "response = requests.get(gif_url)\n",
        "if response.status_code == 200:\n",
        "    # Display the GIF in the notebook\n",
        "    display(Image(url=gif_url))\n",
        "\n",
        "    # Save the GIF in the Colab environment\n",
        "    with open(\"gif_output.gif\", \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    # Show a saved GIF using PIL\n",
        "    saved_gif = PILImage.open(\"gif_output.gif\")\n",
        "    saved_gif.show()\n",
        "else:\n",
        "    print(\"Failed to fetch GIF\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation: This step fetches the generated video from the URL and displays it. It also saves the GIF locally and displays it using PIL if the fetching is successful. Otherwise, it prints an error message."
      ],
      "metadata": {
        "id": "YP4kX1nNoidS"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}